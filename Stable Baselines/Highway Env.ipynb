{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hindsight Experience Replay (HER) with Highway environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will be using the **Highway-env**\n",
    "- [Doumentation)[https://highway-env.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HER\n",
    "HER is a method wrapper that works with off policy methods like **DQN, SAC,TD3, DDPG**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setup the Highway environment by uncommenting the line below!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --user git+https://github.com/eleurent/highway-env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhishek\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Abhishek\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Abhishek\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Abhishek\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Abhishek\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Abhishek\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "## Imports\n",
    "\n",
    "import gym\n",
    "import highway_env\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines import HER, SAC, DDPG, TD3\n",
    "from stable_baselines.ddpg import NormalActionNoise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = gym.make(\"highway-v0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDPG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the environment\n",
    "env = gym.make(\"parking-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Abhishek\\Anaconda3\\lib\\site-packages\\stable_baselines\\ddpg\\policies.py:134: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Abhishek\\Anaconda3\\lib\\site-packages\\stable_baselines\\ddpg\\policies.py:136: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Abhishek\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "--------------------------------------\n",
      "| reference_Q_mean        | -1.16    |\n",
      "| reference_Q_std         | 0.987    |\n",
      "| reference_action_mean   | -0.175   |\n",
      "| reference_action_std    | 0.926    |\n",
      "| reference_actor_Q_mean  | -1.12    |\n",
      "| reference_actor_Q_std   | 0.986    |\n",
      "| rollout/Q_mean          | -0.998   |\n",
      "| rollout/actions_mean    | -0.188   |\n",
      "| rollout/actions_std     | 0.621    |\n",
      "| rollout/episode_steps   | 99.2     |\n",
      "| rollout/episodes        | 100      |\n",
      "| rollout/return          | -53.2    |\n",
      "| rollout/return_history  | -53.2    |\n",
      "| success rate            | 0.01     |\n",
      "| total/duration          | 473      |\n",
      "| total/episodes          | 100      |\n",
      "| total/epochs            | 1        |\n",
      "| total/steps             | 9998     |\n",
      "| total/steps_per_second  | 21.2     |\n",
      "| train/loss_actor        | 1.07     |\n",
      "| train/loss_critic       | 0.00604  |\n",
      "| train/param_noise_di... | 0        |\n",
      "--------------------------------------\n",
      "\n",
      "--------------------------------------\n",
      "| reference_Q_mean        | -1.87    |\n",
      "| reference_Q_std         | 1.81     |\n",
      "| reference_action_mean   | -0.16    |\n",
      "| reference_action_std    | 0.874    |\n",
      "| reference_actor_Q_mean  | -1.81    |\n",
      "| reference_actor_Q_std   | 1.79     |\n",
      "| rollout/Q_mean          | -1.39    |\n",
      "| rollout/actions_mean    | -0.131   |\n",
      "| rollout/actions_std     | 0.676    |\n",
      "| rollout/episode_steps   | 99.3     |\n",
      "| rollout/episodes        | 201      |\n",
      "| rollout/return          | -46      |\n",
      "| rollout/return_history  | -38.6    |\n",
      "| success rate            | 0.02     |\n",
      "| total/duration          | 921      |\n",
      "| total/episodes          | 201      |\n",
      "| total/epochs            | 1        |\n",
      "| total/steps             | 19998    |\n",
      "| total/steps_per_second  | 21.7     |\n",
      "| train/loss_actor        | 1.47     |\n",
      "| train/loss_critic       | 0.0202   |\n",
      "| train/param_noise_di... | 0        |\n",
      "--------------------------------------\n",
      "\n",
      "--------------------------------------\n",
      "| reference_Q_mean        | -2.32    |\n",
      "| reference_Q_std         | 2.35     |\n",
      "| reference_action_mean   | -0.0117  |\n",
      "| reference_action_std    | 0.897    |\n",
      "| reference_actor_Q_mean  | -2.24    |\n",
      "| reference_actor_Q_std   | 2.32     |\n",
      "| rollout/Q_mean          | -1.73    |\n",
      "| rollout/actions_mean    | -0.0862  |\n",
      "| rollout/actions_std     | 0.704    |\n",
      "| rollout/episode_steps   | 97.4     |\n",
      "| rollout/episodes        | 307      |\n",
      "| rollout/return          | -42.1    |\n",
      "| rollout/return_history  | -34.8    |\n",
      "| success rate            | 0.09     |\n",
      "| total/duration          | 1.38e+03 |\n",
      "| total/episodes          | 307      |\n",
      "| total/epochs            | 1        |\n",
      "| total/steps             | 29998    |\n",
      "| total/steps_per_second  | 21.7     |\n",
      "| train/loss_actor        | 1.73     |\n",
      "| train/loss_critic       | 0.0257   |\n",
      "| train/param_noise_di... | 0        |\n",
      "--------------------------------------\n",
      "\n",
      "--------------------------------------\n",
      "| reference_Q_mean        | -2.59    |\n",
      "| reference_Q_std         | 2.73     |\n",
      "| reference_action_mean   | -0.0415  |\n",
      "| reference_action_std    | 0.895    |\n",
      "| reference_actor_Q_mean  | -2.5     |\n",
      "| reference_actor_Q_std   | 2.7      |\n",
      "| rollout/Q_mean          | -1.79    |\n",
      "| rollout/actions_mean    | -0.0688  |\n",
      "| rollout/actions_std     | 0.708    |\n",
      "| rollout/episode_steps   | 92.5     |\n",
      "| rollout/episodes        | 432      |\n",
      "| rollout/return          | -36.1    |\n",
      "| rollout/return_history  | -20.2    |\n",
      "| success rate            | 0.37     |\n",
      "| total/duration          | 1.97e+03 |\n",
      "| total/episodes          | 432      |\n",
      "| total/epochs            | 1        |\n",
      "| total/steps             | 39998    |\n",
      "| total/steps_per_second  | 20.3     |\n",
      "| train/loss_actor        | 1.78     |\n",
      "| train/loss_critic       | 0.0465   |\n",
      "| train/param_noise_di... | 0        |\n",
      "--------------------------------------\n",
      "\n",
      "--------------------------------------\n",
      "| reference_Q_mean        | -2.73    |\n",
      "| reference_Q_std         | 2.99     |\n",
      "| reference_action_mean   | 0.00733  |\n",
      "| reference_action_std    | 0.896    |\n",
      "| reference_actor_Q_mean  | -2.62    |\n",
      "| reference_actor_Q_std   | 2.95     |\n",
      "| rollout/Q_mean          | -1.79    |\n",
      "| rollout/actions_mean    | -0.0598  |\n",
      "| rollout/actions_std     | 0.714    |\n",
      "| rollout/episode_steps   | 85.8     |\n",
      "| rollout/episodes        | 582      |\n",
      "| rollout/return          | -30.9    |\n",
      "| rollout/return_history  | -15.1    |\n",
      "| success rate            | 0.54     |\n",
      "| total/duration          | 2.55e+03 |\n",
      "| total/episodes          | 582      |\n",
      "| total/epochs            | 1        |\n",
      "| total/steps             | 49998    |\n",
      "| total/steps_per_second  | 19.6     |\n",
      "| train/loss_actor        | 1.73     |\n",
      "| train/loss_critic       | 0.0379   |\n",
      "| train/param_noise_di... | 0        |\n",
      "--------------------------------------\n",
      "\n",
      "--------------------------------------\n",
      "| reference_Q_mean        | -2.79    |\n",
      "| reference_Q_std         | 3.13     |\n",
      "| reference_action_mean   | 0.0601   |\n",
      "| reference_action_std    | 0.883    |\n",
      "| reference_actor_Q_mean  | -2.68    |\n",
      "| reference_actor_Q_std   | 3.08     |\n",
      "| rollout/Q_mean          | -1.79    |\n",
      "| rollout/actions_mean    | -0.051   |\n",
      "| rollout/actions_std     | 0.722    |\n",
      "| rollout/episode_steps   | 82.2     |\n",
      "| rollout/episodes        | 730      |\n",
      "| rollout/return          | -27.8    |\n",
      "| rollout/return_history  | -15.3    |\n",
      "| success rate            | 0.5      |\n",
      "| total/duration          | 3.12e+03 |\n",
      "| total/episodes          | 730      |\n",
      "| total/epochs            | 1        |\n",
      "| total/steps             | 59998    |\n",
      "| total/steps_per_second  | 19.2     |\n",
      "| train/loss_actor        | 1.61     |\n",
      "| train/loss_critic       | 0.0304   |\n",
      "| train/param_noise_di... | 0        |\n",
      "--------------------------------------\n",
      "\n",
      "--------------------------------------\n",
      "| reference_Q_mean        | -2.82    |\n",
      "| reference_Q_std         | 3.19     |\n",
      "| reference_action_mean   | 0.00274  |\n",
      "| reference_action_std    | 0.885    |\n",
      "| reference_actor_Q_mean  | -2.71    |\n",
      "| reference_actor_Q_std   | 3.14     |\n",
      "| rollout/Q_mean          | -1.8     |\n",
      "| rollout/actions_mean    | -0.041   |\n",
      "| rollout/actions_std     | 0.727    |\n",
      "| rollout/episode_steps   | 75.6     |\n",
      "| rollout/episodes        | 925      |\n",
      "| rollout/return          | -24.5    |\n",
      "| rollout/return_history  | -11.3    |\n",
      "| success rate            | 0.76     |\n",
      "| total/duration          | 3.81e+03 |\n",
      "| total/episodes          | 925      |\n",
      "| total/epochs            | 1        |\n",
      "| total/steps             | 69998    |\n",
      "| total/steps_per_second  | 18.4     |\n",
      "| train/loss_actor        | 1.56     |\n",
      "| train/loss_critic       | 0.0249   |\n",
      "| train/param_noise_di... | 0        |\n",
      "--------------------------------------\n",
      "\n",
      "--------------------------------------\n",
      "| reference_Q_mean        | -2.84    |\n",
      "| reference_Q_std         | 3.26     |\n",
      "| reference_action_mean   | 0.0574   |\n",
      "| reference_action_std    | 0.903    |\n",
      "| reference_actor_Q_mean  | -2.74    |\n",
      "| reference_actor_Q_std   | 3.22     |\n",
      "| rollout/Q_mean          | -1.83    |\n",
      "| rollout/actions_mean    | -0.0277  |\n",
      "| rollout/actions_std     | 0.73     |\n",
      "| rollout/episode_steps   | 67.8     |\n",
      "| rollout/episodes        | 1.18e+03 |\n",
      "| rollout/return          | -21.5    |\n",
      "| rollout/return_history  | -8.94    |\n",
      "| success rate            | 0.89     |\n",
      "| total/duration          | 4.41e+03 |\n",
      "| total/episodes          | 1.18e+03 |\n",
      "| total/epochs            | 1        |\n",
      "| total/steps             | 79998    |\n",
      "| total/steps_per_second  | 18.1     |\n",
      "| train/loss_actor        | 1.51     |\n",
      "| train/loss_critic       | 0.0228   |\n",
      "| train/param_noise_di... | 0        |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------\n",
      "| reference_Q_mean        | -2.86    |\n",
      "| reference_Q_std         | 3.37     |\n",
      "| reference_action_mean   | 0.205    |\n",
      "| reference_action_std    | 0.89     |\n",
      "| reference_actor_Q_mean  | -2.74    |\n",
      "| reference_actor_Q_std   | 3.33     |\n",
      "| rollout/Q_mean          | -1.86    |\n",
      "| rollout/actions_mean    | -0.0188  |\n",
      "| rollout/actions_std     | 0.737    |\n",
      "| rollout/episode_steps   | 61.3     |\n",
      "| rollout/episodes        | 1.47e+03 |\n",
      "| rollout/return          | -19.1    |\n",
      "| rollout/return_history  | -9.48    |\n",
      "| success rate            | 0.91     |\n",
      "| total/duration          | 4.86e+03 |\n",
      "| total/episodes          | 1.47e+03 |\n",
      "| total/epochs            | 1        |\n",
      "| total/steps             | 89998    |\n",
      "| total/steps_per_second  | 18.5     |\n",
      "| train/loss_actor        | 1.49     |\n",
      "| train/loss_critic       | 0.021    |\n",
      "| train/param_noise_di... | 0        |\n",
      "--------------------------------------\n",
      "\n",
      "--------------------------------------\n",
      "| reference_Q_mean        | -2.87    |\n",
      "| reference_Q_std         | 3.4      |\n",
      "| reference_action_mean   | 0.0991   |\n",
      "| reference_action_std    | 0.925    |\n",
      "| reference_actor_Q_mean  | -2.77    |\n",
      "| reference_actor_Q_std   | 3.35     |\n",
      "| rollout/Q_mean          | -1.91    |\n",
      "| rollout/actions_mean    | -0.0115  |\n",
      "| rollout/actions_std     | 0.745    |\n",
      "| rollout/episode_steps   | 55       |\n",
      "| rollout/episodes        | 1.82e+03 |\n",
      "| rollout/return          | -17.1    |\n",
      "| rollout/return_history  | -8.4     |\n",
      "| success rate            | 0.97     |\n",
      "| total/duration          | 5.33e+03 |\n",
      "| total/episodes          | 1.82e+03 |\n",
      "| total/epochs            | 1        |\n",
      "| total/steps             | 99998    |\n",
      "| total/steps_per_second  | 18.8     |\n",
      "| train/loss_actor        | 1.46     |\n",
      "| train/loss_critic       | 0.0183   |\n",
      "| train/param_noise_di... | 0        |\n",
      "--------------------------------------\n",
      "\n",
      "--------------------------------------\n",
      "| reference_Q_mean        | -2.85    |\n",
      "| reference_Q_std         | 3.45     |\n",
      "| reference_action_mean   | 0.154    |\n",
      "| reference_action_std    | 0.904    |\n",
      "| reference_actor_Q_mean  | -2.75    |\n",
      "| reference_actor_Q_std   | 3.39     |\n",
      "| rollout/Q_mean          | -1.94    |\n",
      "| rollout/actions_mean    | -0.00754 |\n",
      "| rollout/actions_std     | 0.751    |\n",
      "| rollout/episode_steps   | 50.7     |\n",
      "| rollout/episodes        | 2.17e+03 |\n",
      "| rollout/return          | -15.7    |\n",
      "| rollout/return_history  | -7.66    |\n",
      "| success rate            | 0.99     |\n",
      "| total/duration          | 5.82e+03 |\n",
      "| total/episodes          | 2.17e+03 |\n",
      "| total/epochs            | 1        |\n",
      "| total/steps             | 109998   |\n",
      "| total/steps_per_second  | 18.9     |\n",
      "| train/loss_actor        | 1.38     |\n",
      "| train/loss_critic       | 0.0275   |\n",
      "| train/param_noise_di... | 0        |\n",
      "--------------------------------------\n",
      "\n",
      "--------------------------------------\n",
      "| reference_Q_mean        | -2.84    |\n",
      "| reference_Q_std         | 3.41     |\n",
      "| reference_action_mean   | 0.112    |\n",
      "| reference_action_std    | 0.928    |\n",
      "| reference_actor_Q_mean  | -2.73    |\n",
      "| reference_actor_Q_std   | 3.37     |\n",
      "| rollout/Q_mean          | -1.96    |\n",
      "| rollout/actions_mean    | -0.00331 |\n",
      "| rollout/actions_std     | 0.756    |\n",
      "| rollout/episode_steps   | 47.4     |\n",
      "| rollout/episodes        | 2.53e+03 |\n",
      "| rollout/return          | -14.6    |\n",
      "| rollout/return_history  | -7.9     |\n",
      "| success rate            | 0.98     |\n",
      "| total/duration          | 6.28e+03 |\n",
      "| total/episodes          | 2.53e+03 |\n",
      "| total/epochs            | 1        |\n",
      "| total/steps             | 119998   |\n",
      "| total/steps_per_second  | 19.1     |\n",
      "| train/loss_actor        | 1.38     |\n",
      "| train/loss_critic       | 0.0175   |\n",
      "| train/param_noise_di... | 0        |\n",
      "--------------------------------------\n",
      "\n",
      "--------------------------------------\n",
      "| reference_Q_mean        | -2.81    |\n",
      "| reference_Q_std         | 3.4      |\n",
      "| reference_action_mean   | 0.156    |\n",
      "| reference_action_std    | 0.923    |\n",
      "| reference_actor_Q_mean  | -2.69    |\n",
      "| reference_actor_Q_std   | 3.36     |\n",
      "| rollout/Q_mean          | -1.99    |\n",
      "| rollout/actions_mean    | 0.00194  |\n",
      "| rollout/actions_std     | 0.761    |\n",
      "| rollout/episode_steps   | 44.4     |\n",
      "| rollout/episodes        | 2.93e+03 |\n",
      "| rollout/return          | -13.7    |\n",
      "| rollout/return_history  | -7.96    |\n",
      "| success rate            | 0.99     |\n",
      "| total/duration          | 6.75e+03 |\n",
      "| total/episodes          | 2.93e+03 |\n",
      "| total/epochs            | 1        |\n",
      "| total/steps             | 129998   |\n",
      "| total/steps_per_second  | 19.3     |\n",
      "| train/loss_actor        | 1.33     |\n",
      "| train/loss_critic       | 0.0145   |\n",
      "| train/param_noise_di... | 0        |\n",
      "--------------------------------------\n",
      "\n",
      "--------------------------------------\n",
      "| reference_Q_mean        | -2.84    |\n",
      "| reference_Q_std         | 3.52     |\n",
      "| reference_action_mean   | 0.147    |\n",
      "| reference_action_std    | 0.931    |\n",
      "| reference_actor_Q_mean  | -2.73    |\n",
      "| reference_actor_Q_std   | 3.47     |\n",
      "| rollout/Q_mean          | -2.01    |\n",
      "| rollout/actions_mean    | 0.0068   |\n",
      "| rollout/actions_std     | 0.765    |\n",
      "| rollout/episode_steps   | 42.1     |\n",
      "| rollout/episodes        | 3.33e+03 |\n",
      "| rollout/return          | -13      |\n",
      "| rollout/return_history  | -7.42    |\n",
      "| success rate            | 0.99     |\n",
      "| total/duration          | 7.22e+03 |\n",
      "| total/episodes          | 3.33e+03 |\n",
      "| total/epochs            | 1        |\n",
      "| total/steps             | 139998   |\n",
      "| total/steps_per_second  | 19.4     |\n",
      "| train/loss_actor        | 1.27     |\n",
      "| train/loss_critic       | 0.0205   |\n",
      "| train/param_noise_di... | 0        |\n",
      "--------------------------------------\n",
      "\n",
      "--------------------------------------\n",
      "| reference_Q_mean        | -2.77    |\n",
      "| reference_Q_std         | 3.51     |\n",
      "| reference_action_mean   | 0.142    |\n",
      "| reference_action_std    | 0.924    |\n",
      "| reference_actor_Q_mean  | -2.65    |\n",
      "| reference_actor_Q_std   | 3.48     |\n",
      "| rollout/Q_mean          | -2.02    |\n",
      "| rollout/actions_mean    | 0.0115   |\n",
      "| rollout/actions_std     | 0.769    |\n",
      "| rollout/episode_steps   | 40.2     |\n",
      "| rollout/episodes        | 3.73e+03 |\n",
      "| rollout/return          | -12.4    |\n",
      "| rollout/return_history  | -7.95    |\n",
      "| success rate            | 0.97     |\n",
      "| total/duration          | 7.75e+03 |\n",
      "| total/episodes          | 3.73e+03 |\n",
      "| total/epochs            | 1        |\n",
      "| total/steps             | 149998   |\n",
      "| total/steps_per_second  | 19.4     |\n",
      "| train/loss_actor        | 1.25     |\n",
      "| train/loss_critic       | 0.0124   |\n",
      "| train/param_noise_di... | 0        |\n",
      "--------------------------------------\n",
      "\n",
      "--------------------------------------\n",
      "| reference_Q_mean        | -2.81    |\n",
      "| reference_Q_std         | 3.64     |\n",
      "| reference_action_mean   | 0.13     |\n",
      "| reference_action_std    | 0.902    |\n",
      "| reference_actor_Q_mean  | -2.69    |\n",
      "| reference_actor_Q_std   | 3.61     |\n",
      "| rollout/Q_mean          | -2.03    |\n",
      "| rollout/actions_mean    | 0.0154   |\n",
      "| rollout/actions_std     | 0.772    |\n",
      "| rollout/episode_steps   | 38.7     |\n",
      "| rollout/episodes        | 4.14e+03 |\n",
      "| rollout/return          | -11.9    |\n",
      "| rollout/return_history  | -8.29    |\n",
      "| success rate            | 0.99     |\n",
      "| total/duration          | 8.46e+03 |\n",
      "| total/episodes          | 4.14e+03 |\n",
      "| total/epochs            | 1        |\n",
      "| total/steps             | 159998   |\n",
      "| total/steps_per_second  | 18.9     |\n",
      "| train/loss_actor        | 1.22     |\n",
      "| train/loss_critic       | 0.0207   |\n",
      "| train/param_noise_di... | 0        |\n",
      "--------------------------------------\n",
      "\n",
      "--------------------------------------\n",
      "| reference_Q_mean        | -2.71    |\n",
      "| reference_Q_std         | 3.47     |\n",
      "| reference_action_mean   | 0.055    |\n",
      "| reference_action_std    | 0.923    |\n",
      "| reference_actor_Q_mean  | -2.6     |\n",
      "| reference_actor_Q_std   | 3.42     |\n",
      "| rollout/Q_mean          | -2.05    |\n",
      "| rollout/actions_mean    | 0.0199   |\n",
      "| rollout/actions_std     | 0.775    |\n",
      "| rollout/episode_steps   | 37.4     |\n",
      "| rollout/episodes        | 4.54e+03 |\n",
      "| rollout/return          | -11.6    |\n",
      "| rollout/return_history  | -7.51    |\n",
      "| success rate            | 0.99     |\n",
      "| total/duration          | 9.14e+03 |\n",
      "| total/episodes          | 4.54e+03 |\n",
      "| total/epochs            | 1        |\n",
      "| total/steps             | 169998   |\n",
      "| total/steps_per_second  | 18.6     |\n",
      "| train/loss_actor        | 1.16     |\n",
      "| train/loss_critic       | 0.024    |\n",
      "| train/param_noise_di... | 0        |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------\n",
      "| reference_Q_mean        | -2.72    |\n",
      "| reference_Q_std         | 3.49     |\n",
      "| reference_action_mean   | 0.0903   |\n",
      "| reference_action_std    | 0.924    |\n",
      "| reference_actor_Q_mean  | -2.6     |\n",
      "| reference_actor_Q_std   | 3.44     |\n",
      "| rollout/Q_mean          | -2.06    |\n",
      "| rollout/actions_mean    | 0.0245   |\n",
      "| rollout/actions_std     | 0.778    |\n",
      "| rollout/episode_steps   | 36.4     |\n",
      "| rollout/episodes        | 4.94e+03 |\n",
      "| rollout/return          | -11.3    |\n",
      "| rollout/return_history  | -8.27    |\n",
      "| success rate            | 1        |\n",
      "| total/duration          | 9.78e+03 |\n",
      "| total/episodes          | 4.94e+03 |\n",
      "| total/epochs            | 1        |\n",
      "| total/steps             | 179998   |\n",
      "| total/steps_per_second  | 18.4     |\n",
      "| train/loss_actor        | 1.12     |\n",
      "| train/loss_critic       | 0.0208   |\n",
      "| train/param_noise_di... | 0        |\n",
      "--------------------------------------\n",
      "\n",
      "--------------------------------------\n",
      "| reference_Q_mean        | -2.68    |\n",
      "| reference_Q_std         | 3.45     |\n",
      "| reference_action_mean   | -0.0021  |\n",
      "| reference_action_std    | 0.941    |\n",
      "| reference_actor_Q_mean  | -2.57    |\n",
      "| reference_actor_Q_std   | 3.41     |\n",
      "| rollout/Q_mean          | -2.07    |\n",
      "| rollout/actions_mean    | 0.0286   |\n",
      "| rollout/actions_std     | 0.78     |\n",
      "| rollout/episode_steps   | 35.5     |\n",
      "| rollout/episodes        | 5.36e+03 |\n",
      "| rollout/return          | -11      |\n",
      "| rollout/return_history  | -7.48    |\n",
      "| success rate            | 0.99     |\n",
      "| total/duration          | 1.04e+04 |\n",
      "| total/episodes          | 5.36e+03 |\n",
      "| total/epochs            | 1        |\n",
      "| total/steps             | 189998   |\n",
      "| total/steps_per_second  | 18.2     |\n",
      "| train/loss_actor        | 1.01     |\n",
      "| train/loss_critic       | 0.0184   |\n",
      "| train/param_noise_di... | 0        |\n",
      "--------------------------------------\n",
      "\n",
      "--------------------------------------\n",
      "| reference_Q_mean        | -2.75    |\n",
      "| reference_Q_std         | 3.63     |\n",
      "| reference_action_mean   | 0.00754  |\n",
      "| reference_action_std    | 0.947    |\n",
      "| reference_actor_Q_mean  | -2.63    |\n",
      "| reference_actor_Q_std   | 3.57     |\n",
      "| rollout/Q_mean          | -2.08    |\n",
      "| rollout/actions_mean    | 0.0323   |\n",
      "| rollout/actions_std     | 0.782    |\n",
      "| rollout/episode_steps   | 34.6     |\n",
      "| rollout/episodes        | 5.78e+03 |\n",
      "| rollout/return          | -10.7    |\n",
      "| rollout/return_history  | -7.51    |\n",
      "| success rate            | 1        |\n",
      "| total/duration          | 1.11e+04 |\n",
      "| total/episodes          | 5.78e+03 |\n",
      "| total/epochs            | 1        |\n",
      "| total/steps             | 199998   |\n",
      "| total/steps_per_second  | 18       |\n",
      "| train/loss_actor        | 0.988    |\n",
      "| train/loss_critic       | 0.00809  |\n",
      "| train/param_noise_di... | 0        |\n",
      "--------------------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error: the file her_sac_highway could not be found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-57aa7745a0ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# Load saved model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHER\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'her_sac_highway'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\stable_baselines\\her\\her.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, load_path, env, custom_objects, **kwargs)\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m         \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_from_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'policy_kwargs'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'policy_kwargs'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'policy_kwargs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\stable_baselines\\common\\base_class.py\u001b[0m in \u001b[0;36m_load_from_file\u001b[1;34m(load_path, load_data, custom_objects)\u001b[0m\n\u001b[0;32m    649\u001b[0m                     \u001b[0mload_path\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\".zip\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Error: the file {} could not be found\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m         \u001b[1;31m# Open the zip archive and load data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error: the file her_sac_highway could not be found"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create 4 artificial transitions per real transition\n",
    "n_sampled_goal = 4\n",
    "\n",
    "\n",
    "# DDPG Hyperparams:\n",
    "n_actions = env.action_space.shape[0]\n",
    "noise_std = 0.2\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=noise_std * np.ones(n_actions))\n",
    "model = HER('MlpPolicy', env, DDPG, n_sampled_goal=n_sampled_goal,\n",
    "            goal_selection_strategy='future',\n",
    "            verbose=1, buffer_size=int(1e6),\n",
    "            actor_lr=1e-3, critic_lr=1e-3, action_noise=action_noise,\n",
    "            gamma=0.95, batch_size=256,\n",
    "            policy_kwargs=dict(layers=[256, 256, 256]))\n",
    "\n",
    "# let the model train\n",
    "model.learn(int(2e5))\n",
    "\n",
    "# save the model\n",
    "model.save('her_DDPG_highway')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Abhishek\\Anaconda3\\lib\\site-packages\\stable_baselines\\ddpg\\policies.py:134: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Abhishek\\Anaconda3\\lib\\site-packages\\stable_baselines\\ddpg\\policies.py:136: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Abhishek\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Reward: -6.665189025199015 Success? True\n",
      "Reward: -9.272048486238864 Success? True\n",
      "Reward: -18.948234519426858 Success? False\n",
      "Reward: -7.495822589721772 Success? True\n",
      "Reward: -4.163689306686708 Success? True\n",
      "Reward: -5.840025696418903 Success? True\n",
      "Reward: -7.573293624171734 Success? True\n",
      "Reward: -8.061730834635167 Success? True\n",
      "Reward: -8.495039411956311 Success? True\n",
      "Reward: -7.568169131425729 Success? True\n",
      "Reward: -3.9270800468810343 Success? True\n",
      "Reward: -6.3166356176978855 Success? True\n",
      "Reward: -5.359973935183271 Success? True\n",
      "Reward: -7.818963965696212 Success? True\n",
      "Reward: -4.644471910266799 Success? True\n",
      "Reward: -8.71973014470466 Success? True\n",
      "Reward: -10.87722947661791 Success? True\n",
      "Reward: -5.411126343230236 Success? True\n",
      "Reward: -8.20770307499187 Success? True\n",
      "Reward: -10.77347139406573 Success? True\n",
      "Reward: -4.325075710715923 Success? True\n",
      "Reward: -9.465351864453595 Success? True\n",
      "Reward: -10.82668799644049 Success? True\n",
      "Reward: -8.743462434600781 Success? True\n",
      "Reward: -5.340730428000656 Success? True\n",
      "Reward: -7.332403146730108 Success? True\n",
      "Reward: -9.139852536383074 Success? True\n",
      "Reward: -5.352243402208383 Success? True\n",
      "Reward: -7.080872875822595 Success? True\n",
      "Reward: -4.202212247540731 Success? True\n",
      "Reward: -3.3169128740196268 Success? True\n",
      "Reward: -5.779735642815916 Success? True\n",
      "Reward: -5.302730254614796 Success? True\n",
      "Reward: -5.148661176752544 Success? True\n",
      "Reward: -5.498422072263997 Success? True\n",
      "Reward: -6.352625172908144 Success? True\n",
      "Reward: -6.7085108550287 Success? True\n",
      "Reward: -9.317985589222586 Success? True\n",
      "Reward: -9.489338369020823 Success? True\n",
      "Reward: -9.604712079593376 Success? True\n",
      "Reward: -8.45539893023648 Success? True\n",
      "Reward: -6.805650544033717 Success? True\n",
      "Reward: -7.877365877140427 Success? True\n",
      "Reward: -10.750528191080555 Success? True\n"
     ]
    }
   ],
   "source": [
    "model = HER.load('her_DDPG_highway', env=env)\n",
    "\n",
    "obs = env.reset()\n",
    "\n",
    "# Evaluate the agent\n",
    "episode_reward = 0\n",
    "for _ in range(1000):\n",
    "    action, _ = model.predict(obs)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "    episode_reward += reward\n",
    "    if done or info.get('is_success', False):\n",
    "        print(\"Reward:\", episode_reward, \"Success?\", info.get('is_success', False))\n",
    "        episode_reward = 0.0\n",
    "        obs = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets look at the trained agent!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"video/highway-env 2020-12-19 00-05-08.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets open and look at the video saved in our system while running the previous tab\n",
    "\n",
    "# import lib to display\n",
    "from IPython.display import Video\n",
    "\n",
    "#locate the file\n",
    "Video(\"video/highway-env 2020-12-19 00-05-08.mp4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
