{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets the try ACER poly with ATARI Environment\n",
    "ACER- Sample Efficient Actor-Critic with Experience Replay (ACER). It combines several ideas of previous algorithms: it uses multiple workers (as A2C), implements a replay buffer (as in DQN), uses Retrace for Q-value estimation, importance sampling and a trust region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "\n",
    "from stable_baselines.common.cmd_util import make_atari_env\n",
    "from stable_baselines.common.policies import CnnPolicy\n",
    "from stable_baselines.common.vec_env import VecFrameStack\n",
    "from stable_baselines import ACER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There already exists an environment generator that will make and wrap atari environments correctly.\n",
    "env = make_atari_env('PongNoFrameskip-v4', num_env=4, seed=0)\n",
    "# Stack 4 frames\n",
    "env = VecFrameStack(env, n_stack=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Abhishek\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Abhishek\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0        |\n",
      "| avg_norm_g          | 0.0511   |\n",
      "| avg_norm_grads_f    | 0.0511   |\n",
      "| avg_norm_k          | 2.45     |\n",
      "| avg_norm_k_dot_g    | 0.0511   |\n",
      "| entropy             | 151      |\n",
      "| explained_variance  | -0.0974  |\n",
      "| fps                 | 0        |\n",
      "| loss                | -1.51    |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.00733 |\n",
      "| loss_policy         | -0.00733 |\n",
      "| loss_q              | 6.07e-05 |\n",
      "| mean_episode_length | 0        |\n",
      "| mean_episode_reward | 0        |\n",
      "| norm_grads          | 0.0146   |\n",
      "| norm_grads_policy   | 0.00591  |\n",
      "| norm_grads_q        | 0.0133   |\n",
      "| total_timesteps     | 80       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.428    |\n",
      "| avg_norm_g          | 3.24     |\n",
      "| avg_norm_grads_f    | 2.98     |\n",
      "| avg_norm_k          | 2.45     |\n",
      "| avg_norm_k_dot_g    | 3.24     |\n",
      "| entropy             | 150      |\n",
      "| explained_variance  | -0.00271 |\n",
      "| fps                 | 31       |\n",
      "| loss                | -2.31    |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.929   |\n",
      "| loss_policy         | -0.929   |\n",
      "| loss_q              | 0.237    |\n",
      "| mean_episode_length | 879      |\n",
      "| mean_episode_reward | -20.4    |\n",
      "| norm_grads          | 1.67     |\n",
      "| norm_grads_policy   | 0.605    |\n",
      "| norm_grads_q        | 1.56     |\n",
      "| total_timesteps     | 8080     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines.acer.acer_simple.ACER at 0x1a15b98b7c8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the model\n",
    "\n",
    "model = ACER(CnnPolicy, env, verbose=1)\n",
    "model.learn(total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model \n",
    "\n",
    "model.save(\"acer_pong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading a model without an environment, this model cannot be trained until it has a valid environment.\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "trained_model = ACER.load(\"acer_pong\", verbose=1)\n",
    "\n",
    "# load the environment\n",
    "env = make_atari_env('PongNoFrameskip-v4', num_env=4, seed=0)\n",
    "env = VecFrameStack(env, n_stack=4)\n",
    "trained_model.set_env(env)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
