{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q learning for Gird world game\n",
    "\n",
    "This notebook has implementation of Q-learning for grid world game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from: https://github.com/lazyprogrammer/machine_learning_examples/tree/master/rl\n",
    "# the Q-Learning method to find the optimal policy and value function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gridWorldGame import standard_grid, negative_grid,print_values, print_policy\n",
    "\n",
    "SMALL_ENOUGH = 1e-3\n",
    "GAMMA = 0.9\n",
    "ALL_POSSIBLE_ACTIONS = ('U', 'D', 'L', 'R')\n",
    "ALPHA = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_dict(d):\n",
    "  # returns the argmax (key) and max (value) from a dictionary\n",
    "  max_key = None\n",
    "  max_val = float('-inf')\n",
    "  for k, v in d.items():\n",
    "    if v > max_val:\n",
    "      max_val = v\n",
    "      max_key = k\n",
    "  return max_key, max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_action(a, eps=0.1):\n",
    "  # epsilon-soft to ensure all states are visited\n",
    "  p = np.random.random()\n",
    "  if p < (1 - eps):\n",
    "    return a\n",
    "  else:\n",
    "    return np.random.choice(ALL_POSSIBLE_ACTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:\n",
      "---------------------------\n",
      "-0.10|-0.10|-0.10| 1.00|\n",
      "---------------------------\n",
      "-0.10| 0.00|-0.10|-1.00|\n",
      "---------------------------\n",
      "-0.10|-0.10|-0.10|-0.10|\n"
     ]
    }
   ],
   "source": [
    "grid = negative_grid(step_cost=-0.1)\n",
    "\n",
    "# print rewards\n",
    "print(\"rewards:\")\n",
    "print_values(grid.rewards, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 0): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (1, 3): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (2, 1): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (2, 3): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (1, 0): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (0, 3): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (0, 1): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (1, 2): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (2, 0): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (2, 2): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (0, 2): {'U': 0, 'D': 0, 'L': 0, 'R': 0}}\n"
     ]
    }
   ],
   "source": [
    "# no policy initialization, policy is derived from most recent Q like SARSA\n",
    "\n",
    "# initialize Q(s,a)\n",
    "Q = {}\n",
    "states = grid.all_states()\n",
    "for s in states:\n",
    "  Q[s] = {}\n",
    "  for a in ALL_POSSIBLE_ACTIONS:\n",
    "    Q[s][a] = 0\n",
    "\n",
    "# initial Q values for all states in grid\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_counts = {}\n",
    "update_counts_sa = {}\n",
    "for s in states:\n",
    "  update_counts_sa[s] = {}\n",
    "  for a in ALL_POSSIBLE_ACTIONS:\n",
    "    update_counts_sa[s][a] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0\n",
      "iteration: 2000\n",
      "iteration: 4000\n",
      "iteration: 6000\n",
      "iteration: 8000\n"
     ]
    }
   ],
   "source": [
    "# repeat until convergence\n",
    "t = 1.0\n",
    "deltas = []\n",
    "for it in range(10000):\n",
    "  if it % 100 == 0:\n",
    "    t += 1e-2\n",
    "  if it % 2000 == 0:\n",
    "    print(\"iteration:\", it)\n",
    "\n",
    "  # instead of 'generating' an epsiode, we will PLAY\n",
    "  # an episode within this loop\n",
    "  s = (2, 0) # start state\n",
    "  grid.set_state(s)\n",
    "\n",
    "  # the first (s, r) tuple is the state we start in and 0\n",
    "  # (since we don't get a reward) for simply starting the game\n",
    "  # the last (s, r) tuple is the terminal state and the final reward\n",
    "  # the value for the terminal state is by definition 0, so we don't\n",
    "  # care about updating it.\n",
    "  a, _ = max_dict(Q[s])\n",
    "  biggest_change = 0\n",
    "  while not grid.game_over():\n",
    "    a = random_action(a, eps=0.5/t) # epsilon-greedy\n",
    "    # random action also works, but slower since you can bump into walls\n",
    "    # a = np.random.choice(ALL_POSSIBLE_ACTIONS)\n",
    "    r = grid.move(a)\n",
    "    s2 = grid.current_state()\n",
    "\n",
    "    # adaptive learning rate\n",
    "    alpha = ALPHA / update_counts_sa[s][a]\n",
    "    update_counts_sa[s][a] += 0.005\n",
    "\n",
    "    # we will update Q(s,a) AS we experience the episode\n",
    "    old_qsa = Q[s][a]\n",
    "    # the difference between SARSA and Q-Learning is with Q-Learning\n",
    "    # we will use this max[a']{ Q(s',a')} in our update\n",
    "    # even if we do not end up taking this action in the next step\n",
    "    a2, max_q_s2a2 = max_dict(Q[s2])\n",
    "    Q[s][a] = Q[s][a] + alpha*(r + GAMMA*max_q_s2a2 - Q[s][a])\n",
    "    biggest_change = max(biggest_change, np.abs(old_qsa - Q[s][a]))\n",
    "\n",
    "    # we would like to know how often Q(s) has been updated too\n",
    "    update_counts[s] = update_counts.get(s,0) + 1\n",
    "\n",
    "    # next state becomes current state\n",
    "    s = s2\n",
    "    a = a2\n",
    "   \n",
    "  deltas.append(biggest_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(deltas)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the policy from Q*\n",
    "# find V* from Q*\n",
    "policy = {}\n",
    "V = {}\n",
    "for s in grid.actions.keys():\n",
    "  a, max_q = max_dict(Q[s])\n",
    "  policy[s] = a\n",
    "  V[s] = max_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update counts:\n",
      "---------------------------\n",
      " 0.03| 0.04| 0.16| 0.00|\n",
      "---------------------------\n",
      " 0.02| 0.00| 0.16| 0.00|\n",
      "---------------------------\n",
      " 0.19| 0.19| 0.18| 0.02|\n"
     ]
    }
   ],
   "source": [
    "print(\"update counts:\")\n",
    "total = np.sum(list(update_counts.values()))\n",
    "for k, v in update_counts.items():\n",
    "  update_counts[k] = float(v) / total\n",
    "print_values(update_counts, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final values:\n",
      "---------------------------\n",
      " 0.62| 0.80| 1.00| 0.00|\n",
      "---------------------------\n",
      " 0.46| 0.00| 0.80| 0.00|\n",
      "---------------------------\n",
      " 0.31| 0.46| 0.62| 0.46|\n",
      "final policy:\n",
      "---------------------------\n",
      "  R  |  R  |  R  |     |\n",
      "---------------------------\n",
      "  U  |     |  U  |     |\n",
      "---------------------------\n",
      "  R  |  R  |  U  |  L  |\n"
     ]
    }
   ],
   "source": [
    "print(\"final values:\")\n",
    "print_values(V, grid)\n",
    "print(\"final policy:\")\n",
    "print_policy(policy, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "The above cell contains the final value and policy for Gird world game in Q-learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
